{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10ee9914",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install Dependencies\n",
    "# ! pip install datasets librosa scikit-learn tensorflow joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d81f35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#Import Libraries\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e535f74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample example structure:\n",
      "{'audio': {'path': 'C:\\\\Users\\\\hp\\\\.cache\\\\huggingface\\\\hub\\\\datasets--CSALT--deepfake_detection_dataset_urdu\\\\snapshots\\\\eb8f16623108324867e4424a646937409c64b82b\\\\Bonafide\\\\Speaker_01\\\\Part 1\\\\10.wav', 'array': array([ 0.00000000e+00,  0.00000000e+00, -3.05175781e-05, ...,\n",
      "        7.32421875e-04,  1.22070312e-03,  1.28173828e-03]), 'sampling_rate': 16000}}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "# Load the real dataset from Hugging Face\n",
    "ds = load_dataset(\"CSALT/deepfake_detection_dataset_urdu\")\n",
    "audio_data = ds['train']\n",
    "\n",
    "# Check one sample to understand structure (contains audio array, sampling_rate, and path)\n",
    "print(\"Sample example structure:\")\n",
    "print(audio_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e61f796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract MFCC features from audio\n",
    "def extract_mfcc(audio_data):\n",
    "    y = audio_data['array']\n",
    "    sr = audio_data['sampling_rate']\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    return np.mean(mfccs.T, axis=0)\n",
    "\n",
    "# Extract features and actual labels from dataset\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "for i, example in enumerate(audio_data):\n",
    "    try:\n",
    "        mfcc = extract_mfcc(example['audio'])\n",
    "        features.append(mfcc)\n",
    "\n",
    "        # âœ… Now using real labels from the file path\n",
    "        file_path = example['audio']['path'].lower()\n",
    "\n",
    "        if 'bonafide' in file_path:\n",
    "            label = 'bonafide'\n",
    "        elif 'deepfake' in file_path:\n",
    "            label = 'deepfake'\n",
    "        else:\n",
    "            print(f\"Unknown label in path: {file_path}\")\n",
    "            continue  # Skip this file if label not found\n",
    "\n",
    "        labels.append(label)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing example {i}: {e}\")\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "X = np.array(features)\n",
    "y = np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c61c8ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler5.joblib']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode Labels and Train-Test Split\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)  # bonafide -> 0, deepfake -> 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "joblib.dump(scaler, \"scaler5.joblib\")  # Save scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4897c0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       681\n",
      "           1       0.97      0.98      0.97       678\n",
      "\n",
      "    accuracy                           0.97      1359\n",
      "   macro avg       0.97      0.97      0.97      1359\n",
      "weighted avg       0.97      0.97      0.97      1359\n",
      "\n",
      "ROC AUC: 0.9936779592738424\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['svm_model5.joblib']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train SVM\n",
    "svm_model = SVC(probability=True)\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "print(\"SVM Report:\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, svm_model.predict_proba(X_test)[:, 1]))\n",
    "joblib.dump(svm_model, \"svm_model5.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aba5dd3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.78      0.80       681\n",
      "           1       0.79      0.82      0.80       678\n",
      "\n",
      "    accuracy                           0.80      1359\n",
      "   macro avg       0.80      0.80      0.80      1359\n",
      "weighted avg       0.80      0.80      0.80      1359\n",
      "\n",
      "ROC AUC: 0.8828549027761534\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['logistic_model5.joblib']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Logistic Regression\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "print(\"Logistic Regression Report:\")\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, lr_model.predict_proba(X_test)[:, 1]))\n",
    "joblib.dump(lr_model, \"logistic_model5.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b816e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.63      0.70       681\n",
      "           1       0.69      0.84      0.76       678\n",
      "\n",
      "    accuracy                           0.73      1359\n",
      "   macro avg       0.74      0.73      0.73      1359\n",
      "weighted avg       0.74      0.73      0.73      1359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Single-Layer Perceptron\n",
    "perceptron = Perceptron()\n",
    "perceptron.fit(X_train, y_train)\n",
    "y_pred_perc = perceptron.predict(X_test)\n",
    "print(\"Perceptron Report:\")\n",
    "print(classification_report(y_test, y_pred_perc))\n",
    "\n",
    "# Note: Perceptron does not support probability prediction directly\n",
    "# so we skip AUC or use workaround if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7d1f08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "170/170 [==============================] - 4s 8ms/step - loss: 0.4342 - accuracy: 0.8287 - val_loss: 0.2990 - val_accuracy: 0.8896\n",
      "Epoch 2/20\n",
      "170/170 [==============================] - 1s 4ms/step - loss: 0.2294 - accuracy: 0.9152 - val_loss: 0.2081 - val_accuracy: 0.9220\n",
      "Epoch 3/20\n",
      "170/170 [==============================] - 1s 3ms/step - loss: 0.1594 - accuracy: 0.9382 - val_loss: 0.1668 - val_accuracy: 0.9419\n",
      "Epoch 4/20\n",
      "170/170 [==============================] - 1s 4ms/step - loss: 0.1249 - accuracy: 0.9531 - val_loss: 0.1426 - val_accuracy: 0.9529\n",
      "Epoch 5/20\n",
      "170/170 [==============================] - 1s 5ms/step - loss: 0.1023 - accuracy: 0.9643 - val_loss: 0.1261 - val_accuracy: 0.9603\n",
      "Epoch 6/20\n",
      "170/170 [==============================] - 1s 5ms/step - loss: 0.0868 - accuracy: 0.9685 - val_loss: 0.1143 - val_accuracy: 0.9662\n",
      "Epoch 7/20\n",
      "170/170 [==============================] - 1s 7ms/step - loss: 0.0735 - accuracy: 0.9761 - val_loss: 0.1036 - val_accuracy: 0.9713\n",
      "Epoch 8/20\n",
      "170/170 [==============================] - 2s 9ms/step - loss: 0.0647 - accuracy: 0.9785 - val_loss: 0.0955 - val_accuracy: 0.9779\n",
      "Epoch 9/20\n",
      "170/170 [==============================] - 3s 16ms/step - loss: 0.0570 - accuracy: 0.9807 - val_loss: 0.0876 - val_accuracy: 0.9787\n",
      "Epoch 10/20\n",
      "170/170 [==============================] - 1s 7ms/step - loss: 0.0503 - accuracy: 0.9842 - val_loss: 0.0928 - val_accuracy: 0.9765\n",
      "Epoch 11/20\n",
      "170/170 [==============================] - 1s 4ms/step - loss: 0.0466 - accuracy: 0.9849 - val_loss: 0.0845 - val_accuracy: 0.9787\n",
      "Epoch 12/20\n",
      "170/170 [==============================] - 1s 5ms/step - loss: 0.0411 - accuracy: 0.9871 - val_loss: 0.0813 - val_accuracy: 0.9816\n",
      "Epoch 13/20\n",
      "170/170 [==============================] - 1s 5ms/step - loss: 0.0368 - accuracy: 0.9890 - val_loss: 0.0849 - val_accuracy: 0.9816\n",
      "Epoch 14/20\n",
      "170/170 [==============================] - 1s 5ms/step - loss: 0.0340 - accuracy: 0.9899 - val_loss: 0.0794 - val_accuracy: 0.9823\n",
      "Epoch 15/20\n",
      "170/170 [==============================] - 1s 5ms/step - loss: 0.0310 - accuracy: 0.9912 - val_loss: 0.0759 - val_accuracy: 0.9853\n",
      "Epoch 16/20\n",
      "170/170 [==============================] - 1s 3ms/step - loss: 0.0279 - accuracy: 0.9925 - val_loss: 0.0762 - val_accuracy: 0.9845\n",
      "Epoch 17/20\n",
      "170/170 [==============================] - 1s 4ms/step - loss: 0.0249 - accuracy: 0.9930 - val_loss: 0.0892 - val_accuracy: 0.9816\n",
      "Epoch 18/20\n",
      "170/170 [==============================] - 1s 3ms/step - loss: 0.0231 - accuracy: 0.9948 - val_loss: 0.0816 - val_accuracy: 0.9838\n",
      "Epoch 19/20\n",
      "170/170 [==============================] - 1s 3ms/step - loss: 0.0223 - accuracy: 0.9939 - val_loss: 0.0793 - val_accuracy: 0.9845\n",
      "Epoch 20/20\n",
      "170/170 [==============================] - 1s 6ms/step - loss: 0.0203 - accuracy: 0.9941 - val_loss: 0.0841 - val_accuracy: 0.9831\n",
      "43/43 [==============================] - 0s 2ms/step\n",
      "DNN Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       681\n",
      "           1       0.98      0.98      0.98       678\n",
      "\n",
      "    accuracy                           0.98      1359\n",
      "   macro avg       0.98      0.98      0.98      1359\n",
      "weighted avg       0.98      0.98      0.98      1359\n",
      "\n",
      "ROC AUC: 0.9948496701449803\n"
     ]
    }
   ],
   "source": [
    "# Train Deep Neural Network\n",
    "dnn_model = Sequential([\n",
    "    Dense(64, input_shape=(X_train.shape[1],), activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "dnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "dnn_model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n",
    "y_pred_dnn = dnn_model.predict(X_test).ravel()\n",
    "y_pred_dnn_labels = (y_pred_dnn > 0.5).astype(int)\n",
    "print(\"DNN Report:\")\n",
    "print(classification_report(y_test, y_pred_dnn_labels))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_pred_dnn))\n",
    "dnn_model.save(\"dnn_model5.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84baff93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  Accuracy  Precision    Recall        F1       AUC\n",
      "0                  SVM  0.974246   0.966618  0.982301  0.974396  0.993678\n",
      "1  Logistic Regression  0.799853   0.788352  0.818584  0.803184  0.882855\n",
      "2           Perceptron  0.731420   0.690158  0.837758  0.756829       N/A\n",
      "3                  DNN  0.983076   0.983752  0.982301  0.983026   0.99485\n"
     ]
    }
   ],
   "source": [
    "# Summary Table\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate(model_name, y_true, y_pred, y_proba=None):\n",
    "    return {\n",
    "        \"Model\": model_name,\n",
    "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"Precision\": precision_score(y_true, y_pred),\n",
    "        \"Recall\": recall_score(y_true, y_pred),\n",
    "        \"F1\": f1_score(y_true, y_pred),\n",
    "        \"AUC\": roc_auc_score(y_true, y_proba) if y_proba is not None else \"N/A\"\n",
    "    }\n",
    "\n",
    "results = [\n",
    "    evaluate(\"SVM\", y_test, y_pred_svm, svm_model.predict_proba(X_test)[:, 1]),\n",
    "    evaluate(\"Logistic Regression\", y_test, y_pred_lr, lr_model.predict_proba(X_test)[:, 1]),\n",
    "    evaluate(\"Perceptron\", y_test, y_pred_perc),\n",
    "    evaluate(\"DNN\", y_test, y_pred_dnn_labels, y_pred_dnn)\n",
    "]\n",
    "\n",
    "summary_df = pd.DataFrame(results)\n",
    "print(summary_df)\n",
    "summary_df.to_csv(\"model_summary.csv\", index=False)  # Save summary to CSV\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
